{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Check 2 - Say Cheese!"
      ],
      "metadata": {
        "id": "ccgHJBWQxk_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please rename the file before uploading to canvas as: **YourBCEmail_kc2.ipynb**, e.g. it would be steffese_kc2.ipynb for me."
      ],
      "metadata": {
        "id": "DsssfKm9-r3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I really like cheese. So much in fact, that I would like to create a checklist of all cheeses based on [https://www.cheese.com/](https://www.cheese.com/)."
      ],
      "metadata": {
        "id": "cX9xobQHYgS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "a-DZD_88xq3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"polite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7ogmByzySt",
        "outputId": "8ffa7320-2492-4e8a-8472-ab5689ae08aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rcpp’, ‘globals’, ‘listenv’, ‘parallelly’, ‘assertthat’, ‘spiderbar’, ‘future’, ‘future.apply’, ‘ratelimitr’, ‘robotstxt’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(tidyverse)\n",
        "library(rvest)\n",
        "library(polite)\n",
        "library(httr2)\n",
        "library(jsonlite)\n",
        "library(stringr)\n",
        "\n",
        "options(scipen = 999) # to prevent scientific notation\n"
      ],
      "metadata": {
        "id": "XmQgGOYAxwcD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now it's your turn:"
      ],
      "metadata": {
        "id": "HhmG3trmvWn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.) Suburls and Parameters (2 Points)\n",
        "\n",
        "Let's start by going to the [https://www.cheese.com/](https://www.cheese.com/) url. From the main url navigate through the different sorting options at the top (Alphabetical, Cheeses by Type, Cheeses by Milk, ...) and click through some suburls. Notice how the url's query parameters change (i.e. after the `?`).\n",
        "\n",
        "List at least 4 query parameter names, one example value they take, and what they do.\n",
        "\n",
        "For example: Under [https://www.cheese.com/by_milk/](https://www.cheese.com/by_milk/), we have the parameter `m=`, which takes a type of animal milk as its argument, i.e. `m=goat`. This leads us to suburls for cheeses that are made from goat's milk:\n",
        "[https://www.cheese.com/by_milk/?m=goat](https://www.cheese.com/by_milk/?m=goat)\n"
      ],
      "metadata": {
        "id": "ZFxSR9Qqhirf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:**"
      ],
      "metadata": {
        "id": "1lPPSrUpthWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "t=fresh-firm (selects cheese denoted as the fresh-firm type)\n",
        "c=AR (selects cheese based on which country, in this case argentina)\n",
        "i=e (selects cheeses based on first letter, in this case 'e')\n",
        "t=brittle (selects cheeses by texture, in this case brittle)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pP6ENEPZtd4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.) The GOAT cheese (5 Points)\n",
        "\n",
        "My favorite cheese is made from goat milk. Navigate to the suburl for cheeses made from goat's milk, namely [https://www.cheese.com/by_milk/?m=goat](https://www.cheese.com/by_milk/?m=goat), and scrape all the cheeses from the first page.\n",
        "For each cheese scrape its name and its suburl."
      ],
      "metadata": {
        "id": "jYozMhopkMgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:**"
      ],
      "metadata": {
        "id": "hycxsBQNvHjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url <- \"https://www.cheese.com/by_milk/?m=goat\"\n",
        "webpage <- read_html(url)\n",
        "\n",
        "cheese_nodes <- webpage %>% html_nodes(\"h3 a\")\n",
        "\n",
        "cheese_names <- cheese_nodes %>% html_text()\n",
        "cheese_suburls <- cheese_nodes %>% html_attr(\"href\")\n",
        "\n",
        "cheese_data <- tibble(\n",
        "  name = cheese_names,\n",
        "  suburl = cheese_suburls\n",
        ")\n",
        "\n",
        "print(cheese_data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uVPo69Vojarc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0a0a0e-1cda-4abd-b62d-d7891c16167d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m# A tibble: 20 × 2\u001b[39m\n",
            "   name                          suburl                        \n",
            "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                         \n",
            "\u001b[90m 1\u001b[39m Acapella                      /acapella/                    \n",
            "\u001b[90m 2\u001b[39m Ackawi                        /ackawi/                      \n",
            "\u001b[90m 3\u001b[39m Aged Chelsea                  /aged-chelsea/                \n",
            "\u001b[90m 4\u001b[39m Aged Gouda                    /aged-gouda/                  \n",
            "\u001b[90m 5\u001b[39m Ailsa Craig                   /ailsa-craig/                 \n",
            "\u001b[90m 6\u001b[39m Alex James Co. No 4 Goats'    /alex-james-co-no-4-goats/    \n",
            "\u001b[90m 7\u001b[39m Allium Piper                  /allium-piper/                \n",
            "\u001b[90m 8\u001b[39m Alpicrème                     /alpicreme/                   \n",
            "\u001b[90m 9\u001b[39m Alverca                       /alverca/                     \n",
            "\u001b[90m10\u001b[39m Amalthée                      /amalthee/                    \n",
            "\u001b[90m11\u001b[39m Amarelo de Beira Baixa        /amarelo-de-beira-baixa/      \n",
            "\u001b[90m12\u001b[39m Anari                         /anari/                       \n",
            "\u001b[90m13\u001b[39m Anejo Enchilado               /anejo-enchilado/             \n",
            "\u001b[90m14\u001b[39m Anneau du Vic-Bilh            /anneau-du-vic-bilh/          \n",
            "\u001b[90m15\u001b[39m Anthotyro                     /anthotyro/                   \n",
            "\u001b[90m16\u001b[39m Anthotyro Fresco              /anthotyro-fresco/            \n",
            "\u001b[90m17\u001b[39m Aphrodite Goat Milk Halloumi  /aphrodite-haloumi/           \n",
            "\u001b[90m18\u001b[39m Applewood Smoked Chevre       /applewood-smoked-chevre/     \n",
            "\u001b[90m19\u001b[39m Aragon                        /aragon/                      \n",
            "\u001b[90m20\u001b[39m Ardsallagh Hard Goat's Cheese /ardsallagh-hard-goats-cheese/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.) All the cheese! (8 Points)\n",
        "I want to try all the GOAT cheeses - so let's scrape them all.\n",
        "\n",
        "1. First, bow polite to the host url. Tell it your name and get the total number of pages from\n",
        "\n",
        "[https://www.cheese.com/by_milk/?per_page=20&m=goat](https://www.cheese.com/by_milk/?per_page=20&m=goat) using the code below. Explain what each piece does.\n",
        "\n",
        "2. Second, identify which url query parameter determines the page number.\n",
        "\n",
        "3. Third, write a `polite` function called `scrape_cheese()` that takes a `page_num` argument and returns a dataframe with the name and url of each cheese.\n",
        "\n",
        "4. Finally, set up our for loop or (purrr:map()) and scrape all goat cheeses into one big dataframe.\n",
        "\n",
        "*Hint: Take a look at the Metacritic example from our class7 code.*\n"
      ],
      "metadata": {
        "id": "k0MMOv9_lXAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:**|"
      ],
      "metadata": {
        "id": "RIPScJ31Dve4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.)\n",
        "\n",
        "base_url <- \"https://www.cheese.com/by_milk/\"\n",
        "\n",
        "host <- polite::bow(\n",
        "  url = base_url,\n",
        "  user_agent = \"Declan Deegan\", # identify yourself\n",
        "  force = TRUE\n",
        ")\n",
        "host\n",
        "\n",
        "html <- polite::nod(bow = host, path = base_url) |>\n",
        "  polite::scrape()\n",
        "\n",
        "total_pages <- html |>\n",
        "  rvest::html_element(\"div#id_page\") |>\n",
        "  rvest::html_elements(\"div:last-child\") |>\n",
        "  rvest::html_text2() |>\n",
        "  readr::parse_number()\n",
        "\n",
        "str_glue(\"The total number of pages is: {total_pages}.\")"
      ],
      "metadata": {
        "id": "_ORM3y3y1zHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ba3e1eb5-20bb-4fad-b281-203b269e361b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<polite session> https://www.cheese.com/by_milk/\n",
              "    User-agent: Declan Deegan\n",
              "    robots.txt: 0 rules are defined for 1 bots\n",
              "   Crawl delay: 5 sec\n",
              "  The path is scrapable for this user-agent"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'The total number of pages is: 22.'"
            ],
            "text/markdown": "'The total number of pages is: 22.'",
            "text/latex": "'The total number of pages is: 22.'",
            "text/plain": [
              "The total number of pages is: 22."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.)**\n",
        "\n",
        "1. **Initialization**:\n",
        "    - Set the `base_url` variable to the base URL of the cheese website.\n",
        "  \n",
        "2. **Polite Web Scraping**:\n",
        "    - Use the `polite::bow` function to create a respectful session to the website, identifying the user with the agent name \"Declan Deegan\".\n",
        "    - The `force = TRUE` argument ensures the session is recreated even if it already exists.\n",
        "\n",
        "3. **Scraping the Webpage**:\n",
        "    - Use the `polite::nod` function to navigate to the desired URL (`base_url`).\n",
        "    - Apply the `polite::scrape` function to retrieve the content of the webpage and store it in the `html` variable.\n",
        "\n",
        "4. **Extracting Total Number of Pages**:\n",
        "    - Use `rvest` functions to navigate and extract the total number of pages from a specific element on the webpage (assumed to be in a `div` with the ID \"id_page\").\n",
        "    - The `html_element` and `html_elements` functions target specific parts of the HTML, with `div:last-child` presumably targeting the last `div` inside the container, which contains the total number of pages.\n",
        "    - The `html_text2` function retrieves the textual content of the targeted element.\n",
        "    - `readr::parse_number` extracts the numeric value from the text, assuming it might have some non-numeric characters.\n",
        "\n",
        "5. **Output**:\n",
        "    - Use `str_glue` to construct and print a message indicating the total number of pages.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "34pD5qXB3EGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.)**\n",
        "\n",
        "page="
      ],
      "metadata": {
        "id": "yWmLujj24YFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_cheese <- function(page_num) {\n",
        "  base_url <- \"https://www.cheese.com/by_milk/\"\n",
        "\n",
        "  # Assuming the URL query parameter for page number is \"page\" based on our earlier discussion\n",
        "  full_url <- paste0(base_url, \"?m=goat&page=\", page_num)\n",
        "\n",
        "  # Create a polite session\n",
        "  host <- polite::bow(url = base_url, user_agent = \"Your Name\", force = TRUE)\n",
        "\n",
        "  # Navigate to the desired page and scrape its content\n",
        "  html <- polite::nod(bow = host, path = full_url) %>%\n",
        "    polite::scrape()\n",
        "\n",
        "  # Assuming cheese names are within `h3` tags and the suburls are within `a` tags nested inside those `h3` tags\n",
        "  # You might need to adjust these selectors based on the website's structure\n",
        "  cheese_nodes <- html %>% html_nodes(\"h3 a\")\n",
        "\n",
        "  cheese_names <- cheese_nodes %>% html_text()\n",
        "  cheese_suburls <- cheese_nodes %>% html_attr(\"href\")\n",
        "\n",
        "  # Combine the names and suburls into a tibble (dataframe)\n",
        "  cheese_data <- tibble(\n",
        "    name = cheese_names,\n",
        "    suburl = cheese_suburls\n",
        "  )\n",
        "\n",
        "  return(cheese_data)\n",
        "}"
      ],
      "metadata": {
        "id": "fMZRHsN8jiG8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.)\n",
        "# List of all page numbers\n",
        "all_pages <- 1:total_pages\n",
        "\n",
        "# Use map_df to apply the scrape_cheese function to each page and combine results into one dataframe\n",
        "all_cheeses <- map_df(all_pages, scrape_cheese)\n",
        "\n",
        "print(all_cheeses)\n"
      ],
      "metadata": {
        "id": "LPaUig6c08VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442d6561-7679-4c2e-e39d-7fe7e05be27e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m# A tibble: 440 × 2\u001b[39m\n",
            "   name                       suburl                    \n",
            "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                     \n",
            "\u001b[90m 1\u001b[39m Acapella                   /acapella/                \n",
            "\u001b[90m 2\u001b[39m Ackawi                     /ackawi/                  \n",
            "\u001b[90m 3\u001b[39m Aged Chelsea               /aged-chelsea/            \n",
            "\u001b[90m 4\u001b[39m Aged Gouda                 /aged-gouda/              \n",
            "\u001b[90m 5\u001b[39m Ailsa Craig                /ailsa-craig/             \n",
            "\u001b[90m 6\u001b[39m Alex James Co. No 4 Goats' /alex-james-co-no-4-goats/\n",
            "\u001b[90m 7\u001b[39m Allium Piper               /allium-piper/            \n",
            "\u001b[90m 8\u001b[39m Alpicrème                  /alpicreme/               \n",
            "\u001b[90m 9\u001b[39m Alverca                    /alverca/                 \n",
            "\u001b[90m10\u001b[39m Amalthée                   /amalthee/                \n",
            "\u001b[90m# ℹ 430 more rows\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.) Future Research (1 Point)\n",
        "\n",
        "Briefly describe a potential next step one could take to build something useful with these data."
      ],
      "metadata": {
        "id": "qhMpk8btmehp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:**\n",
        "\n",
        "You could create a cheese reccomendation system based on shared attributes or types.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Uy314jyDrVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5vRwDoWICvEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.) Where can I watch this show? (9 Points)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s6rshAn_pk2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an API key from [https://api.watchmode.com/](https://api.watchmode.com/).\n",
        "\n",
        "The WatchMode API allows you to look up shows and movies and can tell you which streaming services they are available on.\n",
        "\n",
        "To do that we first need to get the unique id of the show or movie that we are interested. So let's search for the show \"Breaking Bad\" to find its id.\n",
        "\n",
        "1. Look at the documentation and identify the data endpoint that allows us to **search** for shows and films. What is the endpoint and which query parameters can it take? *Hint: Take a look at the [documentation](https://api.watchmode.com/docs/).*\n",
        "\n",
        "2. Make the request to the API *Hint: Look at the ProPublica code snippet from class code 7.*\n",
        "\n",
        "3. Turn the returned JSON file into a dataframe and pull out the id for Breaking Bad. *Hint: Use the `simplifyVector = TRUE` option for `resp_body_json().*\n",
        "\n",
        "4. Use the Title Streaming Sources API (under Title APIs) to get a list of all streaming services that one can watch Breaking Bad on. `Filter` the dataframe for type == \"sub\" to see subscription options. Where can we watch Breaking Bad for free? What's the url?\n",
        "\n",
        "(**Optional.** Turn your code into a function that takes a show or movie title as an input and returns a list of streaming services it is available on. (You can assume that the first search result has the correct id)."
      ],
      "metadata": {
        "id": "f89QNkfPPciX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:**"
      ],
      "metadata": {
        "id": "r7ZggfdZQ33w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.)**\n",
        "\n",
        "Search for titles or people using an external ID (IMDB, TheMovieDB.org), or by name. Returns an array of results objects, that can either be a title or a person. Useful for getting the Watchmode IDs for titles and people. For example, you can set the parameters to search_value=Breaking%20Bad and search_field=name to get all of the titles named \"Breaking bad\", and then use the IDs returned in other endpoints such as /v1/title/"
      ],
      "metadata": {
        "id": "BFIPxUNqQ53n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.)\n",
        "wm_api_key <- \"LryOk5A3gy21gNwocaenIToPd97BmzGQskWkmqWx\"\n",
        "\n",
        "\n",
        "url <- str_c(\"https://api.watchmode.com/v1/search/?apiKey=\", wm_api_key, \"&\", \"search_field=name\", \"&\", \"search_value=Breaking Bad\")\n",
        "\n",
        "\n",
        "req <- request(\"https://api.watchmode.com/v1/search/?apiKey=\")\n",
        "\n",
        "req <- req |>\n",
        "  req_url_query(\n",
        "    \"apiKey\" = wm_api_key,\n",
        "    \"search_field\"       = 'name',\n",
        "    \"search_value\"       = \"Breaking Bad\"\n",
        "  )\n",
        "\n",
        "  req\n",
        "\n",
        "  resp <- req_perform(req)\n",
        "  resp\n"
      ],
      "metadata": {
        "id": "Y3ibEC32j2F7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d35c8e-83ba-4ff8-9a5e-f6ad3a69d725"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m<httr2_request>\u001b[39m\n",
            "\n",
            "\u001b[1mGET\u001b[22m\n",
            "https://api.watchmode.com/v1/search/?apiKey=LryOk5A3gy21gNwocaenIToPd97BmzGQskWkmqWx&search_field=name&search_value=Breaking%20Bad\n",
            "\n",
            "\u001b[1mBody\u001b[22m: empty\n",
            "\n",
            "\u001b[34m<httr2_response>\u001b[39m\n",
            "\n",
            "\u001b[1mGET\u001b[22m\n",
            "https://api.watchmode.com/v1/search/?apiKey=LryOk5A3gy21gNwocaenIToPd97BmzGQskWkmqWx&search_field=name&search_value=Breaking%20Bad\n",
            "\n",
            "\u001b[32mStatus\u001b[39m: 200 OK\n",
            "\n",
            "\u001b[32mContent-Type\u001b[39m: application/json\n",
            "\n",
            "\u001b[32mBody\u001b[39m: In memory (1249 bytes)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the response body to a JSON object with simplifyVector = TRUE\n",
        "content_list <- httr2::resp_body_json(resp, simplifyVector = TRUE)\n",
        "\n",
        "# Convert the list to a dataframe/tibble\n",
        "content_df <- as_tibble(content_list$title_results)\n",
        "\n",
        "# Grab the ID for \"Breaking Bad\"\n",
        "# Assuming that the first result is the correct one\n",
        "breaking_bad_id <- content_df$id[content_df$name == \"Breaking Bad\"]\n",
        "\n",
        "# Print the ID\n",
        "print(breaking_bad_id)\n"
      ],
      "metadata": {
        "id": "QIzCh0DFKnZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f26553-4d11-4d25-decd-15f8dd4e3231"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 3173903 1734129 1711631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.)\n",
        "# Get the list of streaming services that have the show or movie.\n",
        "\n",
        "# Define the endpoint for Title Streaming Sources API\n",
        "streaming_endpoint <- str_c(\"https://api.watchmode.com/v1/title/\", breaking_bad_id, \"/sources/\")\n",
        "\n",
        "# Make the request\n",
        "streaming_req <- request(streaming_endpoint)\n",
        "streaming_req <- streaming_req |>\n",
        "  req_url_query(\n",
        "    \"apiKey\" = wm_api_key\n",
        "  )\n",
        "\n",
        "# Get the response\n",
        "streaming_resp <- req_perform(streaming_req)\n",
        "\n",
        "# Convert the response to a dataframe\n",
        "streaming_df <- httr2::resp_body_json(streaming_resp, simplifyVector = TRUE) %>% as_tibble()\n",
        "\n",
        "# Filter for subscription options\n",
        "subscription_df <- streaming_df %>% filter(type == \"sub\")\n",
        "\n",
        "# Check where \"Breaking Bad\" can be watched for free\n",
        "free_sources <- subscription_df %>% filter(monetization_type == \"free\")\n",
        "\n",
        "# Extract and print the URL(s)\n",
        "free_urls <- free_sources$url\n",
        "print(free_urls)\n"
      ],
      "metadata": {
        "id": "1F1D6_xwZuBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "49ba197f-e7c9-46ec-e713-95d147f361ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1m\u001b[33mError\u001b[39m in `new_request()`:\u001b[22m\n\u001b[33m!\u001b[39m `url` must be a string\nTraceback:\n",
            "1. request(streaming_endpoint)",
            "2. new_request(base_url)",
            "3. abort(\"`url` must be a string\")",
            "4. signal_abort(cnd, .file)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "neVKRXtZTBTP"
      }
    }
  ]
}